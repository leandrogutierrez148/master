{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"6Yy3jw50SNfn"},"source":["# **Técnicas Avanzadas de Machine Learning**\n","\n","---\n","---\n","<!-- Star Wars: Episodio VII - El despertar de la Fuerza -->\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<img src='https://upload.wikimedia.org/wikipedia/commons/4/49/Star_Wars_The_Force_Awakens.jpg' width=\"650\" height=\"300\" />\n","\n","</figure></center>\n","\n","Fuente de la imagen: [Wikipedia](https://es.wikipedia.org/wiki/Star_Wars:_Episodio_VII_-_El_despertar_de_la_Fuerza)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EynPeG5MJIvR"},"source":["# **Índice**\n","\n","---\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"n9IZNVKCJUEA"},"source":["> [1 - Deep Learning](#scrollTo=yVFeew0Ia839)\n",">> [1.1. AlexNet y la irrupción del Deep Learning (o \"El despertar de la fuerza\")](#scrollTo=vLBEGumzI_S5)\n",">>\n",">> [1.2. Factores que han potenciado el Deep Learning](#scrollTo=EnDwAyU7cSOS)\n",">>\n",">> [1.3. Mejoras en algoritmos](#scrollTo=ZcQBMt25eOuv)\n",">>\n",">>> [1.3.1. Redes Neuronales Recurrentes - LSTM](#scrollTo=BNZ3m3UkVd3J)\n",">>>\n",">>> [1.3.2. Funciones de activación alternativas](#scrollTo=twflWFxt0SO4)\n",">>>\n",">>> [1.3.3. Limitación del gradiente (Gradient Clipping)](#scrollTo=vziqMvhVAWr9)\n",">>>\n",">>> [1.3.4. Inicialización de los pesos](#scrollTo=gXdgQO_UdM4N)\n",">>>\n",">>> [1.3.5. Optimizadores de descenso de gradiente](#scrollTo=gXdgQO_UdM4N)\n",">>>\n",">>> [1.3.6. Dropout](#scrollTo=dK5ANpMLaqHj)\n",">>>\n",">>> [1.3.7. Batch normalization](#scrollTo=nFbiNhNBeuVG)\n",">>\n",">> [1.4. Creación de datasets masivos con información multimedia](#scrollTo=BCCJvzodWApF)\n",">>\n",">> [1.5. Aumento de capacidad de procesamiento](#scrollTo=vfFiSR4jWedy)\n",">>> [1.5.1. GPU](#scrollTo=zcFmY8DiWRB6)\n",">>>\n",">>> [1.5.2. TPU](#scrollTo=iDuY3gp3WmAI)\n",">>>\n",">>> [1.5.3. Otros aceleradores](#scrollTo=FcLqruo-GbfC)\n",">>>\n",">> [1.6. Difusión del conocimiento](#scrollTo=HeDnixh3vNAl)\n",">>\n",">> [1.7. Ejemplos de casos de uso](#scrollTo=szWCdaPG6Yxx)\n",">>> [1.7.1. Eficiencia energética en data centers](#scrollTo=s1WGHfvT8y1a)\n",">>>\n",">>> [1.7.2. Asistentes de voz](#scrollTo=aqSTL802GWbx)\n",">>>\n",">> [Actividad: Frameworks de Deep Learning](#scrollTo=XM_wf-cHSsjG)\n",">>>\n",">>> [Solución](#scrollTo=RflMpsJ5_m0X&line=1&uniqifier=1)\n",">>>\n","> [Ideas clave](#scrollTo=Ox6b9vhIA8om)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yVFeew0Ia839"},"source":["# 1 - Deep Learning\n","Entre los avances en Redes Neuronales podemos destacar el Perceptrón multicapa, el algoritmo de Backpropagation y las primeras Redes Neuronales Convolucionales o CNN.\n","\n","Durante el segundo invierno de la Inteligencia Artificial (1990-2010, aprox.) se siguieron produciendo avances en Redes Neuronales, como las redes recurrentes LSTM o el uso de funciones de activación alternativas, que junto con otros avances posteriores provocaron la disrupción del Deep Learning que está teniendo lugar en la actualidad y que trataremos en este tema.\n","\n","El término Deep Learning fue acuñado por Geoffrey Hinton en 2006 como evolución importante de las Redes Neuronales: al irse solucionando diversos problemas que dificultaban el entrenamiento, se pudo incrementar la complejidad de las Redes en cuanto a ***número de capas***, que es a lo que se refiere la palabra \"***Deep***\".\n","\n","Veamos algunas de estas mejoras con un ejemplo: la Red Neuronal Convolucional, o CNN, AlexNet.\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vLBEGumzI_S5"},"source":["## 1.1. AlexNet y la irrupción del Deep Learning (o \"El despertar de la fuerza\")\n","\n","Suele indicarse como momento de irrupción del Deep Learning la competición anual ImageNet Large-Scale Visual Recognition Challenge de 2012 (ILSVRC12) porque por primera vez resultó vencedora una Red Neuronal, en concreto la CNN **AlexNet** (Krizhevsky et al., 2012).\n","\n","AlexNet es una evolución de LeNet, la CNN que desarrolló Yann LeCun (LeCun et al., 1989) para clasificar símbolos MNIST. En cuanto a número de capas, tiene **5 capas de convolución**, frente a las 2 de LeNet. Asimismo, adopta **mejoras algorítmicas** como el aumento de datos (data augmentation) o el dropout (que veremos posteriormente).\n","\n","Una de las principales diferencias es que el dataset **ImageNet** sobre el que está entrenada AlexNet es mucho más complejo: la versión de ILSVRC 2012 constaba de **1 millón de imágenes** pertenecientes a **1000 clases** distintas, frente a las 60.000 imágenes de 10 clases distintas en MNIST. Por otra parte, Imagenet está compuesto por imágenes en color de 224 x 224 pixels, frente a las imágenes de dígitos en niveles de gris de 28 x 28 pixels de MNIST.\n","\n","Finalmente, AlexNet utiliza GPU (Graphical Processing Unit) para acelerar los cálculos.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://github.com/md-lorente/Master_BD_DS/raw/main/m%C3%B3dulo_7_aprendizaje_autom%C3%A1tico_para_machine_learning/alexnet.png' width=\"700\" height=\"200\" />\n","<figcaption>Imagen1. Red Convolucional AlexNet (2012) </figcaption></center>\n","</figure>\n","\n","Fuente: [www.cs.toronto.edu](https://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf)\n","\n","Con AlexNet se inició una carrera en las sucesivas competiciones anuales de ILSVRC, que han sido ganadas por modelos de Deep Learning de complejidad creciente y tasas de error decreciente.\n","\n","En la imagen siguiente podemos ver el número de capas y la tasa de error de distintos modelos ganadores de ILSVRC hasta 2016, en que el vencedor fue un modelo de Deep Learning que superaba las 200 capas y obtuvo un 3% de error.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://www.researchgate.net/publication/338797371/figure/fig1/AS:850851782479874@1579870281484/Recent-ConvNets-proposed-in-ILSVRC.png' width=\"600\" height=\"300\" />\n","<figcaption>Imagen2. ILSVRC: Tasa de error y número de capas </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.researchgate.net](https://www.researchgate.net/publication/338797371/figure/fig1/AS:850851782479874@1579870281484/Recent-ConvNets-proposed-in-ILSVRC.png)\n","\n","Para hacernos una idea de cómo ha ido evolucionando la complejidad, basta con observar los modelos VGGNet-19 (modelo de la Universidad de Oxford), compuesto por 19 capas y vencedor de ILSVRC14, y ResNet-34 (de Microsoft), que con 34 capas es una versión reducida del modelo de 152 capas vencedor de ILSVRC15: en solo un año se pasó de las decenas de capas a más de ciento cincuenta.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://github.com/md-lorente/Master_BD_DS/raw/main/m%C3%B3dulo_7_aprendizaje_autom%C3%A1tico_para_machine_learning/resnet-vgg19.png' width=\"700\" height=\"200\" />\n","<figcaption>Imagen3. VGG-19 (2014) y ResNet-34 (2015) </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.arxiv.org](https://arxiv.org/abs/1512.03385)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EnDwAyU7cSOS"},"source":["## 1.2. Factores que han potenciado el Deep Learning\n","Tomando como ejemplo AlexNet, hemos visto algunos de los factores que han potenciado el Deep Learning.\n","\n","En este apartado vamos a realizar un análisis más exhaustivo de estos factores, que son de cuatro tipos:\n","\n","* Mejoras en algoritmos.\n","\n","* Existencia de grandes datasets de imágenes.\n","\n","* Aumento de capacidad de procesamiento.\n","\n","* Difusión del conocimiento.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZcQBMt25eOuv"},"source":["## 1.3. Mejoras en algoritmos\n","\n","Los modelos de Deep Learning han ido integrando mejoras en algoritmos de ámbito diverso: funciones de activación, optimizadores, etc.\n","\n","En este apartado vamos a exponer algunas de estas mejoras, de forma que vayamos desarrollando criterio para trabajar con los framework de Deep Learning.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BNZ3m3UkVd3J"},"source":["### 1.3.1. Redes Neuronales Recurrentes - LSTM\n","De forma equivalente a las Redes Neuronales Convolucionales para imagen, en la década de 1980 se desarrollaron modelos de Redes Neuronales Recurrentes o RNN para texto. Se denominan \"recurrentes\" porque **la propagación se realiza sobre una única capa de forma recurrente**, en lugar de aplicarse sobre capas sucesivas como ocurre en un perceptrón multi-capa.\n","\n","La imagen siguiente muestra esta operativa y su despliegue equivalente:\n","\n","* A la entrada de la RNN se introduce una secuencia $X$ compuesta por \"n\" palabras.\n","\n","* Para cada palabra se realiza una propagación hacia adelante sobre una única capa.\n","\n","* A la salida obtenemos el resultado de la capa en ese instante.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg' width=\"800\" height=\"300\" />\n","<figcaption>Imagen4. Red Neuronal Recurrente desplegada</figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.wikimedia.org](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n","\n","\n","Los primeros modelos presentaban dos limitaciones importantes:\n","\n","1. **Los problemas de gradiente fuera de rango (vanishing y exploding)**, debido a la multiplicación reiterada de los mismos pesos. Este problema se resolvió con la función de activación ReLU, entre otros avances.\n","\n","2. **Solo capturaban relaciones entre palabras muy cercanas.** Esta limitación se aminoró con las redes LSTM, que permiten almacenar relaciones entre palabras alejadas entre sí en secuencias relativamente largas.\n","\n","Veremos las redes LSTM y su aplicación a procesado de lenguaje natural en un tema posterior."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"twflWFxt0SO4"},"source":["### 1.3.2. Funciones de activación alternativas\n","Durante la década de 1990 se identificó que la **sigmoide** no era adecuada como función de activación (aunque sí como clasificador binario) en redes de muchas capas, ya que su derivada alcanza valores reducidos con facilidad, con lo que se corre el riesgo de anulación del gradiente (vanishing gradient) que vimos anteriormente.\n","\n","Por otro lado, se demostró que la **sigmoide** tampoco era adecuada para conseguir que los pesos convergieran adecuadamente durante el entrenamiento de una red de muchas capas debido a que la media de sus valores es positiva.\n","\n","Por estos motivos, se propusieron funciones de activación alternativas, como la Tangente Hiperbólica (tanh) o la ReLU.\n","\n","<br>\n","<font color='Blue'><b> Función tanh </b></font>\n","\n","La función **Tangente Hiperbólica (tanh)** tiene como ventaja sobre la sigmoide que la media de sus valores  es 0, y se define como:\n","\n","$$ a(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n","\n","<br>\n","\n","Junto con la sigmoide, se utiliza internamente en las puertas de las células LSTM."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"elapsed":550,"status":"ok","timestamp":1730660999628,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"gj96TxCd_lJn","outputId":"242f346d-757f-4ac9-ceb5-b16fd4eba37e"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 600x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Imagen5. Función de activación tanh\n"]}],"source":["# Función de activación tanh\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","x = np.linspace(-10, 10, num=100)\n","y = np.tanh(x)\n","\n","plt.figure(figsize=(6, 2))\n","ax = plt.gca()  # gca significa 'get current axis'\n","ax.spines['right'].set_color('none')\n","ax.spines['top'].set_color('none')\n","ax.xaxis.set_ticks_position('bottom')\n","ax.spines['bottom'].set_position(('data',0))\n","ax.yaxis.set_ticks_position('left')\n","ax.spines['left'].set_position(('data',0))\n","plt.plot(x, y, linewidth=5)\n","plt.show()\n","plt.close()\n","print(\"Imagen5. Función de activación tanh\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iUQ-oV1U_H36"},"source":["<br>\n","<font color='Blue'><b> Función ReLU </b></font>\n","\n","La función **ReLU (Rectified Linear Unit)** se define como:\n","\n","$$ f(x) = \\begin{cases}\n","x&\\text{si $x \\geq 0$}\\\\\n","0&\\text{si $x < 0$}\\\\\n","\\end{cases} $$\n","\n","Tiene una ventaja adicional frente a otras funciones de activación, y es que su derivada es trivial, lo que acelera el cálculo de gradientes:\n","\n","$$ f'(x) = \\begin{cases}\n","1&\\text{si $x \\geq 0$}\\\\\n","0&\\text{si $x < 0$}\\\\\n","\\end{cases} $$\n","\n","\\\\\n","\n","Por otro lado, **es robusta con respecto a la anulación del gradiente** (vanishing gradient), que es un problema importante para entrenar redes compuestas por muchas capas.\n","\n","Por estos motivos, la función ReLU es muy utilizada actualmente en los framework de Deep Learning, junto con variantes como LeakyReLU.\n","\n","<br>\n","\n","$\\bbox{Ejemplo.}$\n","\n","Observemos el siguiente ejemplo de la función de activación ReLu:"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"elapsed":1016,"status":"ok","timestamp":1730661006793,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"HLw20B0O8YQ2","outputId":"ed73f63a-5250-4d3e-c752-8b43d5ed7459"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 600x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Imagen6. Función de activación ReLU\n"]}],"source":["# Función de activación ReLU (Rectified Linear Unit)\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","x = np.linspace(-10, 10, num=100)\n","y = np.maximum(0, x) # ReLU\n","\n","plt.figure(figsize=(6, 2))\n","ax = plt.gca()  # gca significa 'get current axis'\n","ax.spines['right'].set_color('none')\n","ax.spines['top'].set_color('none')\n","ax.xaxis.set_ticks_position('bottom')\n","ax.spines['bottom'].set_position(('data',0))\n","ax.yaxis.set_ticks_position('left')\n","ax.spines['left'].set_position(('data',0))\n","plt.plot(x, y, linewidth=5)\n","plt.show()\n","plt.close()\n","print(\"Imagen6. Función de activación ReLU\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vziqMvhVAWr9"},"source":["### 1.3.3. Limitación del gradiente (Gradient Clipping)\n","Con el fin de evitar valores excesivos de gradiente (exploding gradient), los framework de Deep Learning suelen ofrecer funcionalidad de limitación de gradiente (Gradient Clipping), en la que se indica el valor máximo al que queremos limitar el gradiente.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","\n","<center>\n","<img src='https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/gradient-clipping.png?' width=\"600\" height=\"300\" />\n","<figcaption>Imagen7. Ejemplo de Gradient Clipping </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.neptune.ai](https://neptune.ai/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gXdgQO_UdM4N"},"source":["### 1.3.4. Inicialización de los pesos\n","Xavier Glorot demostró que inicializar correctamente los pesos de una Red Neuronal es importante para facilitar su entrenamiento. En concreto (Glorot y Bengio, 2010), aconsejaba inicializarlos siguiendo una distribución gausiana cuya media es 0 y su varianza es inversamente proporcional al número de nodos \"n\" de la capa anterior:\n","\n","$$ W  \\sim N(\\mu=0, \\sigma ^2=\\frac{1}{n}) $$\n","\n","\\\\\n","\n","En los framework de Deep Learning puede encontrarse este tipo de inicialización indistintamente como \"Xavier\" o \"Glorot\".\n","\n","Posteriormente se demostró que para algunas funciones de activación, como ReLU, es preferible la siguiente modificación (He, 2015):\n","\n","$$ W  \\sim N(\\mu=0, \\sigma ^2=\\frac{2}{n}) $$\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AWtpngZX0SVm"},"source":["### 1.3.5. Optimizadores de descenso de gradiente\n","En los últimos años se han desarrollado muchos algoritmos para optimizar el descenso del gradiente, entre los que podemos destacar el **Stochastic Gradient Descent** y el **Adam**.\n","\n","<br>\n","\n","<font color='Blue'><b> Optimizador Stochastic Gradient Descent (SGD) </b></font>\n","\n","Como ya vimos, el algoritmo de retropropagación (backpropagation), que permite entrenar las redes neuronales, se basa en minimizar el error de salida mediante cálculo diferencial, en concreto en el Gradiente Descent.\n","\n","En la práctica, **resulta costoso computacionalmente** aplicar el Gradient Descent a todo el dataset de entrada en cada iteración. Podríamos pensar que una forma de acelerar el entrenamiento de la Red Neuronal es dividir el dataset de entrada en lotes y entrenar la red para un solo lote en cada iteración.\n","\n","Con esta idea, se desarrolló una variación del Gradient Descent en que se sustituye el gradiente real aplicado a todo el dataset por una aproximación del gradiente aplicada a un subconjunto del dataset (un lote o batch). Esta variación se denomina **Stochastic Gradient Descent** o SGD (Cho et al., 2013) ya que el orden del dataset de entrada y sus etiquetas se aleatorizan antes de dividirlo en lotes.\n","\n","SGD es un optimizador típico en los framework de Deep Learning.\n","\n","<br>\n","\n","<font color='Blue'><b> Optimizador Adam </b></font>\n","\n","Adam (ADAptive Moment estimation) es un método de optimización del gradiente que añade momentos de orden 1 y 2 en el cálculo de los gradientes (Kingma y Ba, 2013).\n","\n","En primer lugar se calculan los momentos de orden 1 (media) y 2 (varianza) a partir del gradiente:\n","\n","$$ m_{t+1} = \\beta_1 m_t + (1-\\beta_1)grad_{t+1} \\text{(momento de orden 1)} $$\n","\n","$$ v_{t+1} = \\beta_2 v_t + (1-\\beta_2)grad^2_{t+1} \\text{(momento de orden 2)} $$\n","\n","\\\\\n","\n","A continuación se corrigen los momentos:\n","\n","$$ \\hat m_{t+1} = \\frac {m_{t+1}} {1-\\beta^{t+1}_1} $$\n","\n","$$ \\hat v_{t+1} = \\frac {v_{t+1}} {1-\\beta^{t+1}_2} $$\n","\n","Finalmente, se actualizan los pesos:\n","\n","$$ W_{t+1} = W_t - \\alpha \\frac {\\hat m_{t+1}} {(\\hat v_{t+1} + \\epsilon)} $$\n","\n","\\\\\n","\n","Como vemos, para modular la influencia de los momentos, utiliza otros parámetros ($\\beta_1$, $\\beta_2$ y $\\epsilon$) además de la tasa de aprendizaje $\\alpha$, si bien suelen dar buenos resultados los valores por defecto en los framework de Deep Learning, que son los aconsejados por los autores:\n","\n","$$ \\beta_1=0.9, \\beta_2=0.999  \\text{ y }\\epsilon=10^{-8} $$\n","\n","\n","Actualmente, Adam es uno de los optimizadores más utilizados.\n","\n","<br>\n","<p> <mark>¿SABÍAS QUE...?</mark> </p>\n","<hr>\n","\n","Si en el **optimizador SGD** se da valor a la opción \"**momentum**\" se consigue un comportamiento muy parecido a Adam.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dK5ANpMLaqHj"},"source":["### 1.3.6. Dropout\n","La funcionalidad de **dropout** (Srivastava et al., 2014) se definió para reducir la posibilidad de overfitting.\n","\n","Consiste en el apagado aleatorio de un porcentaje de las conexiones entre dos capas. Con esto se consigue que a la segunda capa raramente lleguen los mismos datos de la primera, lo que impide que haya conexiones demasiado reforzadas y dificulta el overfitting. Otra característica del dropout es que permite entrenar con conjuntos de datos limitados.\n","\n","Como consecuencia lógica, **al añadir capas de dropout** se dificulta el entrenamiento de la red y **se necesita más tiempo para entrenar la red**, aunque se **consiguen mejores resultados.**\n","\n","La funcionalidad de dropout se incluye en los framework de Deep Learning.\n","\n","La imagen siguiente ilustra un ejemplo de dropout con probabilidades 40% y 60% por capa.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://github.com/albertojulian/master-ub/raw/main/dropout.png' width=\"600\" height=\"330\" />\n","<figcaption>Imagen8. Ejemplo de dropout </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.jmlr.org](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n","\n","\n","\n","<br>\n","<p> <mark>IMPORTANTE</mark> </p>\n","<hr>\n","\n","\n","* Como es habitual en cualquier técnica para reducir o evitar overfitting, **dropout solo se aplica en tiempo de entrenamiento**.\n","\n","* Por otro lado, es importante saber que los framework de Deep Learning suelen aplicar un **factor corrector** $\\frac{1}{(1-p)}$ (siendo $p$ la probablidad de dropout) a las conexiones **de forma que la suma de las entradas mantenga su valor**.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nFbiNhNBeuVG"},"source":["### 1.3.7. Batch normalization\n","La normalización a nivel de lote (batch normalization) en cada capa de la Red es un modo de regularizar los pesos de la Red Neuronal y permite acelerar el entrenamiento.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://images.deepai.org/glossary-terms/981e1ffea3814ae193c27461253faf63/batch_normalization.png' width=\"600\" height=\"330\" />\n","<figcaption>Imagen9. Ejemplo de Batch normalization </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.deepai.org](https://deepai.org/machine-learning-glossary-and-terms/batch-normalization)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BCCJvzodWApF"},"source":["## 1.4. Creación de datasets masivos con información multimedia\n","\n","**Los modelos de Deep Learning necesitan un volumen elevado de datos.** Afortunadamente, en los últimos años asistimos a la creación de grandes datasets de información multimedia: imágenes, audio, texto. La ubicuidad de los teléfonos móviles ha facilitado el suministro de información a estos datasets.\n","\n","Las entidades que crean estos datasets tienen distintos motivos: en ocasiones es **favorecer la investigación** en Deep Learning o utilizarlos como banco de pruebas; como ejemplos podemos citar:\n","\n","* **Imagenet**: Base de datos de imágenes ideada por Fei-Fei Li, investigadora de Inteligencia Artificial, compuesta por millones de imágenes pertenecientes a más de 20.000 categorías. Desde 2010 es el dataset en que se apoya la competición anual ILSVRC.\n","\n","* **Corpus de texto** a partir de volcados de **Wikipedia**, con los que entrenar word embeddings, por ejemplo.\n","\n","* **VoxCeleb** para audio hablado: es un dataset de audio extraído de entrevistas de personajes famosos en YouTube. Lo ha creado el grupo de la Universidad de Oxford que diseñó el modelo de Deep Learning VGG-19.\n","\n","Algunas entidades están también motivadas por la **explotación comercial**: empresas de referencia en Deep Learning como *Google*, *Facebook* o *Amazon* entrenan sus modelos en gran medida gracias a información que les proporcionamos los propios usuarios de aplicaciones como Youtube, Facebook, Instagram, Whatsapp o Amazon.\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vfFiSR4jWedy"},"source":["## 1.5. Aumento de capacidad de procesamiento\n","Por un lado, los entornos en la nube facilitan el uso temporal de granjas de servidores.\n","\n","Por otro lado, tanto en la nube como en local, se ha popularizado el uso de procesadores específicos para multiplicación de tensores, como las **GPU** o las **TPU**."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zcFmY8DiWRB6"},"source":["### 1.5.1. GPU\n","Las **GPU** (Graphical Processing Unit, típicamente de NVIDIA), originalmente utilizadas para [renderización](https://biblus.accasoftware.com/es/renderizacion-definicion-tipos-y-tecnicas-de-visualizacion/) rápida de imagen y video, en la gama alta están compuestas de centenares o miles de núcleos de poca capacidad que procesan en paralelo, frente a los pocos núcleos de mayor capacidad que tiene una CPU. La imagen siguiente ilustra esta diferencia.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://github.com/albertojulian/master-ub/raw/main/cpu-and-gpu.jpeg' width=\"400\" height=\"300\" />\n","<figcaption>Imagen10. Núcleos en una CPU y en una GPU </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [https://www.nvidia.com/](https://www.nvidia.com/es-la/drivers/what-is-gpu-computing/)\n","\n","Dado que la operación básica que realizan es multiplicar matrices o tensores, muy frecuente en Deep Learning, se utilizan para acelerar el entrenamiento de modelos de Deep Learning.\n","\n","El Deep Learning se ha aprovechado de la popularización de las GPU alcanzada gracias a las comunidades de gamers, ya que son un elemento imprescindible para ejecutar videojuegos en tiempo real.\n","\n","Por otro lado, los proveedores de servicios cloud como Google Cloud, Microsoft Azure o Amazon AWS dotan a sus servidores de mayor capacidad con GPU.\n","\n","<br>\n","\n","<font color='Blue'><b> Comparativa de tiempo de ejecución entre GPU y PU </b></font>\n","\n","No se puede concretar cuánto puede acelerar una GPU frente a una CPU, ya que depende de las características de ambas y de la complejidad del modelo de Deep Learning\n","\n","A modo de ejemplo, podemos indicar los tiempos de ejecución en una red convolucional sobre Colab:\n","\n","* Sin GPU: <font color='Red'><b> 143 </b></font> segundos.\n","* Con GPU: <font color='Green'><b> 6 </b></font> segundos.\n","\n","<br>\n","<p> <mark>¿SABÍAS QUE...?</mark> </p>\n","<hr>\n","\n","El propio Colab permite utilizar una GPU, habilitándola en \"Entorno de ejecución -> Cambiar tipo de entorno de ejecución\".\n","\n","**Solo debes utilizar GPU en Notebooks que la requieran, ya que su tiempo de utilización está controlado por Google y puedes no tener disponibilidad cuando realmente la necesites.**\n","\n","\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iDuY3gp3WmAI"},"source":["### 1.5.2. TPU\n","Las **TPU** (Tensor Processing Unit) son diseños específicos de Google para Deep Learning desarrollados como alternativa a las GPU. En la actualidad están **disponibles en Google Cloud**.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://upload.wikimedia.org/wikipedia/commons/b/be/Tensor_Processing_Unit_3.0.jpg' width=\"300\" height=\"200\" />\n","<figcaption>Imagen11. Tensor Processing Unit 3.0 </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.wikimedia.org](https://upload.wikimedia.org/wikipedia/commons/b/be/Tensor_Processing_Unit_3.0.jpg)\n","\n","<br>\n","<p> <mark>¿SABÍAS QUE...?</mark> </p>\n","<hr>\n","\n","Como alternativa a una GPU, **Colab permite utilizar una TPU**, habilitándola en \"Entorno de ejecución -> Cambiar tipo de entorno de ejecución\"."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FcLqruo-GbfC"},"source":["### 1.5.3 Otros aceleradores\n","\n","Existen otros dispositivos que permiten acelerar el entrenamiento de modelos de Deep Learning, como las **FPGA** (Field-Programmable Gate Arrays), cuya ventaja es que son **reconfigurables**.\n","\n","Consiguen un **funcionamiento muy rápido** y otra de las ventajas es tenerlo **todo integrado en un chip** y no con elementos electrónicos.\n","\n","Entre las empresas que están adoptando este enfoque, entre ellas, podemos destacar a *Microsoft* e *Intel*.\n","\n","\n","<br>\n","<p> <mark>PARA SABER MÁS</mark> </p>\n","<hr>\n","\n","Te recomendamos la lectura del siguiente enlace para profundizar más sobre las\n","[FPGA y por que jugarán un papel clave en el e futuro](https://planetachatbot.com/que-es-fpga-y-por-que-jugaran-papel-clave-en-futuro/).\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HeDnixh3vNAl"},"source":["## 1.6. Difusión del conocimiento\n","Una última palanca para potenciar el Deep Learning está siendo la difusión del conocimiento en másters (como el nuestro) o MOOCs.\n","\n","Por otro lado, se vienen realizando competiciones de Machine Learning que contribuyen a la formación:\n","\n","* ***Netflix***, en 2009, organizó una competición (con un premio de **US$ 1.000.000**) para mejorar su sistema de recomendación.\n","\n","* ***Kaggle*** es una comunidad web de Machine Learning con competiciones en la que suele haber **espíritu de colaboración**: se comparte código, datasets... Por otra parte, ha ayudado a popularizar herramientas como XGBoost o LightGBM (Microsoft).\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"szWCdaPG6Yxx"},"source":["## 1.7. Ejemplos de casos de uso\n","En este apartado, nos ocupamos de casos de uso que no están relacionados con procesado de imagen o procesado de lenguaje natural, que trataremos en temas posteriores.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"s1WGHfvT8y1a"},"source":["### 1.7.1. Eficiencia energética en data centers\n","En 2014 Google puso en marcha un proyecto de eficiencia energética en Centros de Datos. Uno de los objetivos era predecir la Efectividad en el Uso de la energía (PUE), lo cual permite hacer simulaciones y ajustar elementos de coste elevado como los aparatos de aire acondicionado, resultando en ahorros de coste.\n","\n","En la imagen siguiente se muestra un **esquema simplificado** de la Red Neuronal que utilizan, que en realidad es un **perceptrón con 19 variables de entrada, 5 capas ocultas y 50 nodos por capa**.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://github.com/albertojulian/master-ub/raw/main/DNN-PUE.png' width=\"1000\" height=\"380\" />\n","<figcaption>Imagen12. Esquema simplificado de Red Neuronal para previsión de PUE en Data Centers. </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www./static.googleusercontent.com](https://static.googleusercontent.com/media/research.google.com/es//pubs/archive/42542.pdf) y elaboración propia\n","\n","Podemos ver cómo es de precisa la previsión de la PUE en la imagen siguiente, en la que el intervalo de tiempo entre muestras es de 5 minutos.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Model-accuracy.max-1000x1000.png' width=\"800\" height=\"400\" />\n","<figcaption>Imagen13. PUE prevista frente a real. </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [www.blog.google.com](https://blog.google/inside-google/infrastructure/better-data-centers-through-machine/)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"aqSTL802GWbx"},"source":["### 1.7.2. Asistentes de voz\n","\n","El uso de modelos de Deep Learning para asistentes de voz está creciendo de forma espectacular desde 2016, con empresas como Apple, Baidu, Amazon o Google compitiendo entre sí.\n","\n","En general, el proceso consiste en:\n","\n","* La entrada de estos sistemas es audio de voz que se procesa deslizando una ventana en el eje temporal.\n","\n","* Cada trozo de audio correspondiente a la ventana se transforma por una columna con sus componentes en frecuencia, produciendo lo que se conoce como **espectrograma**.\n","\n","* En ese punto, se puede interpretar la señal como una **imagen** o una **secuencia temporal**.\n","\n","\\\\\n","\n","Dos consideraciones:\n","\n","1. En el caso de considerarla como una imagen, podemos tratarla con **Redes Convolucionales**.\n","\n","2. Si la queremos considerar una secuencia temporal, podemos tratarla con **Redes Recurrentes LSTM**.\n","\n","<br>\n","\n","$\\bbox{Ejemplo.}$\n","\n","Como ejemplo de esta dualidad del Deep Learning aplicado a los espectrogramas podemos citar el modelo de síntesis de voz [WaveNet](https://deepmind.com/blog/article/wavenet-generative-model-raw-audio), basado en Redes Convolucionales, presentado en 2016 y que sintetizaba voz que resultaba muy natural, aunque era muy poco eficiente.\n","\n","Posteriormente, ha sido sustituido por el modelo [WaveRNN](https://arxiv.org/abs/1802.08435v2), que sustituye las capas convolucionales por capas recurrentes y es más rápido de entrenar.\n","\n","<!-- script html for image -->\n","<figure>\n","<center>\n","<br>\n","<center>\n","<img src='https://github.com/albertojulian/master-ub/raw/main/asisvoz.png' width=\"1060\" height=\"600\" />\n","<figcaption>Imagen14. Enfoque de entrada en asistentes de voz. </figcaption></center>\n","</figure>\n","\n","Fuente de la imagen: [Elaboración propia](https://github.com/albertojulian/master-ub/raw/main/asisvoz.png)\n","\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XM_wf-cHSsjG"},"source":["## Actividad: Frameworks de Deep Learning\n","Vamos a realizar un breve recorrido por los distintos modos de funcionamiento de TensorFlow y PyTorch, con ejemplos.\n","\n","Ambos proporcionan diversos tipos de capa: lineal, lstm, convolucional, etc."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RflMpsJ5_m0X"},"source":["### Solución\n","\n","[*A continuación, haz clic para conocer la solución.*]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4IVm7g2I0SZE"},"source":["#### **TensorFlow**\n","El framework de Deep Learning TensorFlow fue desarrollado internamente por Google Brain para uso interno, hasta su publicación en 2015.\n","\n","En la actualidad incluye Keras, una capa de abstracción muy flexible. Junto con Keras, TensorFlow ofrece tres modos de funcionamiento: **Sequential, OOP (Orientado a Objetos) y Functional**.\n","\n","El modo Sequential es el que suele utilizarse para modelos de Deep Learning cuyas capas no tengan entradas de más de una capa anterior, y es con el único que trabajaremos en el módulo."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"U2OOj-cH9EO-"},"source":["<font color='Blue'><b> Importación de paquetes </b></font>\n","\n","Normalmente se importarán paquetes de ***tensorflow.keras*** como:\n","\n","* *models*, que incluye:\n","\n"," * La clase [Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model) (también accesible desde *keras.Model*), de la que debemos heredar al construir nuestra propia clase.\n","\n"," * La clase [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential), que agrupa una *secuencia de capas*.\n","\n"," * Las funciones *save_model* y *load_model*.\n","\n","* [layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers), con clases para construir capas lineales, dropout, convolucionales, lstm, funciones de activación, etc.\n","\n","* [losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses), que incluye clases que calculan la función de pérdidas, como BinaryCrossentropy, CategoricalCrossentropy o MSE.\n","\n","* [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), que incluyen clases que implementan optimizadores como SGD, Adam o RMSprop"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4192,"status":"ok","timestamp":1730661049024,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"AxwxywDZ9Nxu"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import models, layers, losses, optimizers"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MA402IzH60a6"},"source":["<font color='Blue'><b> Carga de datos </b></font>\n","\n","Si queremos cargar un dataset de tensorflow, debemos importar el paquete [datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) de tensorflow.keras, que nos proporciona los datasets mnist, fashion_mnist, cifar10, cifar100, imdb..."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":546,"status":"ok","timestamp":1730661051441,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"7B8F8PR66-n8","outputId":"3e83b0d3-b196-4f07-8e7c-8fffcb18e7bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["from tensorflow.keras import datasets\n","(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OZkUoV91OpAJ"},"source":["<br>\n","<p> <mark>IMPORTANTE</mark> </p>\n","<hr>\n","\n","Debes realizar visualización de los datos para comprobar rangos y dimensiones. Por ejemplo:\n","\n","* **Si las imágenes tienen valores de 0 a 255, conviene normalizarlas** entre -0.5 y 0.5, o entre 0 y 1.\n","\n","* En **datasets multiclase** las etiquetas suelen venir en **una sola columna**, pero la salida de la Red Neuronal será multicolumna (*One Hot Encoded*); puedes utilizar la función **to_categorical** de *tensorflow.keras.utils* para convertirla."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1730661055072,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"MKDd0tuBQ_wF","outputId":"10faeaef-6913-4d1a-a29e-addafb22218d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[5 0 4 1 9]\n","[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"]}],"source":["x_train = x_train / 255.0 # normaliza imágenes con valores de 0 a 255 a valores entre 0 y 1\n","\n","from tensorflow.keras.utils import to_categorical\n","print(y_train[:5]) # una columna\n","y_train_c = to_categorical(y_train)\n","print(y_train_c[:5]) # tantas columnas como clases haya en el dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"k52C1eMI60pJ"},"source":["<font color='Blue'><b> Definición del modelo: Modo Sequential </b></font>\n","\n","El modo Sequential agrupa una serie de capas que se van añadiendo:\n","\n","* En la **primera capa** se debe **indicar la dimensión** de los elementos del dataset de entrada (parámetro **input_shape**).\n","\n","* **En el resto de capas lineales**, convolucionales, etc. **solo se define el número de nodos salientes**, ya que el número de nodos entrantes se deduce de la capa anterior.\n","\n","* En el caso de clasificación multiclase, el número de nodos salientes de la última capa será el de clases a clasificar.\n","\n","Las capas lineales (*clase Dense*), convolucionales, etc. suelen tener un parámetro \"activation\" en el que **se puede indicar la función de activación**(relu, sigmoid, softmax). Aunque algunas como ReLU o Softmax tienen su clase propia.\n","\n","De forma implícita, el modo *Sequential* crea una instancia de la clase *models.Model.*\n","\n","<br>\n","<p> <mark>IMPORTANTE</mark> </p>\n","<hr>\n","\n","Debes **revisar siempre** la arquitectura del modelo con el método **summary()**."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260},"executionInfo":{"elapsed":267,"status":"ok","timestamp":1730661058708,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"pOeBf1ar8nJh","outputId":"76976c72-55b6-4829-ea0e-7807bcd3804a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m7,850\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model_tf = models.Sequential()\n","model_tf.add(layers.Flatten(input_shape=(28, 28, 1))) # dimensión del dataset de entrada\n","model_tf.add(layers.Dense(10, activation=\"softmax\")) # el número de nodos entrantes es el de salientes de Flatten\n","\n","model_tf.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4vlFD13O60wO"},"source":["<font color='Blue'><b> Optimizador, función de coste y métricas </b></font>\n","\n","En TensorFlow se pueden gestionar estos elementos de dos formas:\n","\n","* Como parámetros del método **compile**.\n","\n","* Como clases (ver modo OOP)."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":248,"status":"ok","timestamp":1730661111770,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"PeslyFza8oKA"},"outputs":[],"source":["model_tf.compile(\n","    optimizer=\"adam\",\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lf1ZOfVe601Z"},"source":["<font color='Blue'><b> Entrenamiento </b></font>\n","\n","A semejanza de sklearn, TensorFlow presenta un método **fit** para entrenar el modelo, cuyos parámetros principales son el dataset y las etiquetas, el número de iteraciones, el tamaño de lote, y el porcentaje que queremos usar para validación.\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11660,"status":"ok","timestamp":1730661124884,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"qxGapIvg8tRg","outputId":"94642b3d-2789-4d99-ff5f-e0b952f346c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.0721 - val_accuracy: 0.9147 - val_loss: 0.0676\n","Epoch 2/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.0689 - val_accuracy: 0.9171 - val_loss: 0.0664\n","Epoch 3/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.0690 - val_accuracy: 0.9193 - val_loss: 0.0656\n","Epoch 4/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.0675 - val_accuracy: 0.9200 - val_loss: 0.0650\n","Epoch 5/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.0664 - val_accuracy: 0.9227 - val_loss: 0.0645\n"]}],"source":["history = model_tf.fit(\n","    x_train, y_train_c,\n","    epochs=5,\n","    batch_size=64,\n","    validation_split=0.2\n",")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4sQ9G41D8uJA"},"source":["<font color='Blue'><b> Evaluación </b></font>\n","\n","Puedes hacer predicciones con los datos de pruebas con el método **predict**.\n","\n","Si dispones de etiquetas de prueba, con el método **evaluate** puedes calcular la métrica que indicaste anteriormente en **compile**.\n","\n","<br>\n","<p> <mark>IMPORTANTE</mark> </p>\n","<hr>\n","\n","Si has aplicado **to_categorical** a las etiquetas de entrenamiento, deberás hacer lo mismo con las etiquetas de prueba.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2818,"status":"ok","timestamp":1730661131932,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"7froedS68uRS","outputId":"0788e839-a936-4036-e13c-334b574d91f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 15.9691\n"]}],"source":["y_pred = model_tf.predict(x_test)\n","\n","y_test_c = to_categorical(y_test)\n","test_loss, test_metric = model_tf.evaluate(x_test, y_test_c)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WrYG8CU7owyl"},"source":["<font color='Blue'><b> Tensores, numpy y GPU </b></font>\n","\n","TensorFlow utiliza internamente arrays del tipo general Tensor.\n","\n","Para pasar un Tensor a array de numpy se utiliza el método **numpy()**.\n","\n","El acceso a la GPU es transparente.\n","\n","<br>\n","<p> <mark> RECUERDA </mark> </p>\n","<hr>\n","\n","Si quieres utilizar una GPU, **antes de importar los paquetes debes habilitarla** en \"Entorno de ejecución -> Cambiar tipo de entorno de ejecución\".\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"64lRqbr00Sca"},"source":["#### **PyTorch**\n","\n","El framework PyTorch fue desarrollado por el Laboratorio de Investigación en Inteligencia Artificial de Facebook (FAIR) y liberado en 2017.\n","\n","Al igual que TensorFlow, ofrece un modo de funcionamiento **Sequential**, aunque solo para la definición de modelos sencillos.\n","\n","Por otro lado, para modelos más complicados, y para el resto de etapas (entrenamiento, evaluación) proporciona acceso a toda la funcionalidad con enfoque **OOP (Orientado a Objetos)**.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Nar5_c9EKJ3X"},"source":["<font color='Blue'><b> Importación de paquetes </b></font>\n","\n","Por lo general se importarán paquetes como:\n","\n","* [torch.nn](https://pytorch.org/docs/stable/nn.html), que contiene:\n","\n"," * la clase [Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module), de la que debemos heredar al construir nuestra propia clase.\n","\n"," * la clase [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential), que agrupa una secuencia de capas.\n","\n"," * capas lineales, dropout, convolucionales, lstm, funciones de activación, transformers, etc.\n","\n"," * clases que calculan la función de pérdidas, como CrossEntropyLoss o MSELoss.\n","\n","* [optim](https://pytorch.org/docs/stable/optim.html), que incluyen clases que implementan optimizadores como SGD, Adam o RMSprop."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3703,"status":"ok","timestamp":1730661170136,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"_Njq2k1RKQx-"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.optim as optim"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OblyjmpB608p"},"source":["<font color='Blue'><b> Carga de datos </b></font>\n","\n","Podemos encontrar datasets de imágenes en el paquete **torchvision.datasets**, como MNIST, Fashion-MNIST, CIFAR10, y otros más complejos como CelebA, CocoCaptions, CocoDetection, Flickr8k, Flickr30k...\n","\n","Por otra parte, suele utilizarse la clase **DataLoader** para obtener un iterable de lotes (el tamaño de lote viene dado por **batch_size**).\n","\n","El paquete **torchvision.transforms** incluye clases para transformar el dataset antes de cargarlo.\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8811,"status":"ok","timestamp":1730661178944,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"P-DhDu_ZoYTi","outputId":"344e0be1-929f-4b97-cce9-149f805d74c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 20.1MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28.9k/28.9k [00:00<00:00, 613kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1.65M/1.65M [00:00<00:00, 5.59MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4.54k/4.54k [00:00<00:00, 7.79MB/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from torchvision import datasets, transforms\n","\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","\n","# obtenemos el trainset con el parámetro train=True\n","trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n","# para aleatorizar el trainset => shuffle=True\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","# obtenemos el testset con el parámetro train=False\n","testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n","# no se necesita agitar el testset => shuffle=False\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UH7dhT08wd61"},"source":["<font color='Blue'><b> Definición del modelo: Modo Sequential </b></font>\n","\n","Al igual que ocurre con TensorFlow, el modo Sequential de PyTorch agrupa una serie de capas que se van añadiendo, teniendo en cuenta que:\n","\n","* En todas las capas lineales (*clase Linear*), convolucionales, etc. hay que indicar explícitamente los nodos de entrada y salida.\n","\n","* En el caso de clasificación multiclase, el número de nodos salientes de la última capa será el de clases a clasificar.\n","\n","De forma implícita, crea una instancia de la clase *nn.Module.*\n","\n","<br>\n","<p> <mark>IMPORTANTE</mark> </p>\n","<hr>\n","\n","Debes **revisar siempre** la arquitectura del modelo con **print()**."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1730661183156,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"sQ2Q_UaTweFj","outputId":"e56cfd68-174c-4338-ae7e-618f99a7e128"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (0): Flatten(start_dim=1, end_dim=-1)\n","  (1): Linear(in_features=784, out_features=100, bias=True)\n","  (2): Linear(in_features=100, out_features=10, bias=True)\n","  (3): LogSoftmax(dim=1)\n",")\n"]}],"source":["model_pt = nn.Sequential(nn.Flatten(),\n","                      nn.Linear(784, 100),\n","                      nn.Linear(100, 10),\n","                      nn.LogSoftmax(dim=1))\n","\n","print(model_pt)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HAMdCvKr--Az"},"source":["<font color='Blue'><b> Definición del modelo: Modo OOP (orientado a objetos) </b></font>\n","\n","Podemos definir nuestro propio modelo siguiendo estos pasos:\n","\n","1. Heredar de **nn.Module**.\n","\n","2. Definir el método constructor $\\text{__init__}$ (como en cualquier clase python).\n","\n","3. definir el método **forward**, que ejecuta la propagación hacia adelante (forward propagation).\n","\n","<br>\n","<p> <mark>IMPORTANTE</mark> </p>\n","<hr>\n","\n","El método **forward** se ejecuta implícitamente cuando llamamos a nuestra instancia con un lote como parámetro:\n","\n","```\n","logits = model_pt(x_train) # ejecuta forward\n","```"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1730661187239,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"qphTmB47_QMX","outputId":"9d06ee34-18ef-4482-aa41-24eb47469cb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model_pt(\n","  (flat): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=784, out_features=100, bias=True)\n","  (fc2): Linear(in_features=100, out_features=10, bias=True)\n","  (logsoftmax): LogSoftmax(dim=1)\n",")\n"]}],"source":["class Model_pt(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","      self.flat = nn.Flatten()\n","      self.fc1 = nn.Linear(784, 100) # inicialización\n","      self.fc2 = nn.Linear(100, 10) # inicialización\n","      self.logsoftmax = nn.LogSoftmax(dim=1) # inicialización\n","\n","    def forward(self, x):\n","      # x = torch.flatten(x, start_dim=1) # Alternativa a nn.Flatten()\n","      x = self.flat(x)\n","      x = self.fc1(x)\n","      x = self.fc2(x)\n","      x = self.logsoftmax(x)\n","      return x\n","\n","model_pt = Model_pt() # llamamos al constructor únicamente\n","print(model_pt)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"P0TuC5Z_aIA5"},"source":["<br>\n","<p> <mark> RECUERDA </mark> </p>\n","<hr>\n","\n","**El constructor de una clase** ($\\text{método __init__}$) solo debe utilizarse para inicializar. Salvo la llamada al constructor de la clase madre, super().$\\text{__init__}$(), **no importa el orden de las inicializaciones.**\n","\n","En cambio, en **el resto de métodos**, como forward, suelen ejecutarse acciones en las que el orden de ejecución **SÍ importa**.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FRQGspqW61Fo"},"source":["<font color='Blue'><b> Optimizador, función de coste y métricas </b></font>\n","\n","En PyTorch se utilizan las clases disponibles.\n","\n","Como primer parámetro, a los optimizadores se les pasa un iterable con los parámetros a optimizar (es decir, sobre los que hay que calcular el gradiente)."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1730661241202,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"yObaIXaMzXlE"},"outputs":[],"source":["optimizer = optim.Adam(model_pt.parameters(), lr=0.001)\n","criterion = nn.NLLLoss() # Negative Log Likelihood Loss; NLLL loss + softmax = Cross Entropy"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"I-hOTUyt2CFc"},"source":["Por otro lado, debe ejecutarse el método *step()* del optimizador después de calcularse el gradiente de la pérdida *loss.backward()*."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HPa2Y8un0xu1"},"source":["<font color='Blue'><b> Entrenamiento </b></font>\n","\n","A diferencia de TensorFlow, en PyTorch debe definirse explícitamente el bucle de entrenamiento:\n","\n","* Se define el bucle de épocas (una época es una iteración del dataset completo).\n","\n"," * Para cada época, se itera sobre los bloques del *trainloader*, y para cada bloque se realizan los pasos siguientes:\n","\n","   1. Se inicializan los gradientes de los parámetros para los que se definió el optimizador.\n","\n","   2. Se calcula la salida del modelo para el bloque actual.\n","\n","   3. Se calcula la función de pérdida o coste.\n","\n","   4. Se calculan los gradientes a partir de la pérdida por retropropagación (*backpropagation*).\n","\n","   5. Se actualizan los pesos del modelo aplicando los gradientes a los parámetros para los que se definió el optimizador.\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":93221,"status":"ok","timestamp":1730661336941,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"CE6id0Dp0yDr"},"outputs":[],"source":["epochs = 5\n","model_pt.train()\n","for e in range(epochs):\n","   for x_train, y_train in trainloader:\n","      # inicializa los gradientes de los parámetros\n","      optimizer.zero_grad()\n","      # calcula hacia adelante\n","      logits = model_pt(x_train) # ejecuta el método forward\n","      # calcula la pérdida\n","      loss = criterion(logits, y_train)\n","      # calcula los gradientes a partir de la pérdida\n","      loss.backward()\n","      # actualiza los pesos del modelo aplicando los gradientes a los parámetros\n","      optimizer.step()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BxNxYJT98wkL"},"source":["<font color='Blue'><b> Evaluación </b></font>\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2946,"status":"ok","timestamp":1730661412105,"user":{"displayName":"José Ángel González","userId":"09321900723274188157"},"user_tz":-60},"id":"zLoZdTy18wuG","outputId":"1d6c78bf-2619-44e6-d3ee-f802d73e3fe2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy del modelo sobre el dataset de prueba: 91.01%\n"]}],"source":["correct = 0\n","total = 0\n","# Preparemos el modelo para evaluación, desactivando cualquier capa\n","# que tenga un comportamiento no determinista, e.g., dropout\n","model_pt.eval()\n","\n","# deshabilitamos el cálculo de gradientes en inferencia, tb vale torch.inference_mode()\n","with torch.no_grad():\n","  for x_test, y_test in testloader:\n","    logits = model_pt(x_test) # ejecuta el método forward\n","    # escogemos la clase con mayor valor\n","    _, y_pred = torch.max(logits.data, 1)\n","    total += y_test.size(0)\n","    correct += (y_pred == y_test).sum().item()\n","\n","print(f'Accuracy del modelo sobre el dataset de prueba: {100 * correct / total}%')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OtSet9BbM5wJ"},"source":["<font color='Blue'><b> Tensores, numpy y GPU </b></font>\n","\n","PyTorch utiliza internamente la clase Tensor en la GPU, por lo que debes conocer lo siguiente:\n","\n","* Para saber si se dispone de GPU se utiliza la función **torch.cuda.is_available()**.\n","\n","* Para pasar un **array de numpy a Tensor** se utiliza la función **torch.from_numpy()**.\n","\n","* Para mover un **Tensor o un modelo a la GPU** (NVIDIA) se utiliza el método **cuda()**.\n","\n","* Para pasar un **Tensor a array de numpy** se utiliza el método **numpy()** del Tensor.\n","\n","<br>\n","<p> <mark> RECUERDA </mark> </p>\n","<hr>\n","\n","Si quieres utilizar una GPU, debes habilitarla en \"Entorno de ejecución -> Cambiar tipo de entorno de ejecución\" **antes de importar los paquetes**, ya que al cambiar el tipo de entorno, éste se resetea."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SelQVY112SWm","outputId":"942dcb97-9467-4270-e379-a26e5a3e9565"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'numpy.ndarray'> float64\n","<class 'torch.Tensor'> torch.float64\n","GPU no disponible\n"]}],"source":["import numpy as np\n","\n","array_np = np.random.random([3, 2])\n","print(type(array_np), array_np.dtype)\n","\n","# convertimos array de numpy a Tensor\n","array_pt = torch.from_numpy(array_np)\n","print(type(array_pt), array_pt.dtype)\n","\n","train_on_gpu = torch.cuda.is_available()\n","\n","if train_on_gpu:\n","  print(\"GPU disponible\")\n","  # pasamos Tensor a GPU\n","  array_pt = array_pt.cuda()\n","\n","  # en general, lo que queremos pasar a la GPU es el modelo completo\n","  model_pt.cuda()\n","\n","else:\n","  print(\"GPU no disponible\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ox6b9vhIA8om"},"source":["# **IDEAS CLAVE**\n","<br>\n","<hr>\n","<p> <h1> <center> <strong> Deep Learning </center> </strong> </h1> </p>\n","<hr>\n","<br>\n","\n","\n","* **Hay varios factores que explican la disrupción del Deep Learning**, y varios no tienen que ver con algoritmia (a diferencia de las primeras evoluciones de las Redes Neuronales).\n","\n","* Debe comprenderse que **el Deep Learning continúa evolucionando** y se evaluará su introducción en nuevas áreas.\n","\n","* Sin embargo, **no debe pensarse que el Deep Learning superará a todas las tecnologías actuales** en esas nuevas áreas."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
